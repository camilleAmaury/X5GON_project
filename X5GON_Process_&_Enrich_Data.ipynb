{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "X5GON Process & Enrich Data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCZk606BUzvY",
        "colab_type": "code",
        "outputId": "f5bfa7a2-0271-4b91-ffb4-e7f4bc4f5e86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "! mkdir datasets\n",
        "! wget https://uncloud.univ-nantes.fr/index.php/s/r6W7oixMM48P59k/download\n",
        "! mv download datasets/catalogue.tsv"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-03 20:01:55--  https://uncloud.univ-nantes.fr/index.php/s/r6W7oixMM48P59k/download\n",
            "Resolving uncloud.univ-nantes.fr (uncloud.univ-nantes.fr)... 193.52.104.60, 2001:660:7220:386:193:52:104:60\n",
            "Connecting to uncloud.univ-nantes.fr (uncloud.univ-nantes.fr)|193.52.104.60|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 72971322 (70M) [application/octet-stream]\n",
            "Saving to: ‘download’\n",
            "\n",
            "download            100%[===================>]  69.59M  10.4MB/s    in 8.8s    \n",
            "\n",
            "2019-12-03 20:02:06 (7.89 MB/s) - ‘download’ saved [72971322/72971322]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgVquOWgVSD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vha55wmPVl-F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ff917174-7302-4e6e-eb40-c838020b593f"
      },
      "source": [
        "list_parser = lambda x: x[1:-1].split(',')\n",
        "df = pd.read_csv(\"datasets/catalogue.tsv\",\n",
        "                        sep=\"\\t\",\n",
        "                        converters={'keywords': list_parser,\n",
        "                                    \"concepts\": list_parser})\n",
        "# This is added in case initial dataset hasn't the right columns names:\n",
        "df.columns = ['id', 'title', 'language', 'type', 'keywords', 'concepts']\n",
        "df.head(5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>language</th>\n",
              "      <th>type</th>\n",
              "      <th>keywords</th>\n",
              "      <th>concepts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1228</td>\n",
              "      <td>Data, information, design and traffic injuries...</td>\n",
              "      <td>en</td>\n",
              "      <td>mp4</td>\n",
              "      <td>[design,  know,  information design,  people, ...</td>\n",
              "      <td>['http://en.wikipedia.org/wiki/Information_des...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4796</td>\n",
              "      <td>Uncertain Allies</td>\n",
              "      <td>en</td>\n",
              "      <td>pdf</td>\n",
              "      <td>[north korea,  korea,  china,  north,  pyongya...</td>\n",
              "      <td>['http://en.wikipedia.org/wiki/North_Korea',  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6930</td>\n",
              "      <td>Classification of Web Documents Using a Graph-...</td>\n",
              "      <td>en</td>\n",
              "      <td>mp4</td>\n",
              "      <td>[subgraph,  graph,  document,  contrast,  clas...</td>\n",
              "      <td>['http://en.wikipedia.org/wiki/Hello',  'http:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7867</td>\n",
              "      <td>Cell and Molecular Neurobiology</td>\n",
              "      <td>en</td>\n",
              "      <td>pdf</td>\n",
              "      <td>[edition,  academic press,  molecular,  2nd ed...</td>\n",
              "      <td>['http://en.wikipedia.org/wiki/Massachusetts_I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8160</td>\n",
              "      <td>Advanced Fluid Dynamics of the Environment</td>\n",
              "      <td>en</td>\n",
              "      <td>pdf</td>\n",
              "      <td>[fluid,  eddy viscosity,  result velocity,  fl...</td>\n",
              "      <td>['http://en.wikipedia.org/wiki/Homework',  'ht...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  ...                                           concepts\n",
              "0  1228  ...  ['http://en.wikipedia.org/wiki/Information_des...\n",
              "1  4796  ...  ['http://en.wikipedia.org/wiki/North_Korea',  ...\n",
              "2  6930  ...  ['http://en.wikipedia.org/wiki/Hello',  'http:...\n",
              "3  7867  ...  ['http://en.wikipedia.org/wiki/Massachusetts_I...\n",
              "4  8160  ...  ['http://en.wikipedia.org/wiki/Homework',  'ht...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5Hv40zzWMEU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d61ecb5b-6ec9-427b-f743-4fa14ccab58e"
      },
      "source": [
        "def MeanAndMedianArrayLength(df, colname):\n",
        "    mean = 0\n",
        "    median_tab = []\n",
        "    for i in range(0, len(df)):\n",
        "        add = len(df.loc[i,colname])\n",
        "        mean += add\n",
        "        median_tab.append(add)\n",
        "    mean = mean / len(df)\n",
        "    print(\"mean of \" + colname + \" numbers : \" + str(mean))\n",
        "    median_tab = np.sort(np.array(median_tab))\n",
        "    middle = int(len(median_tab)/2)\n",
        "    if len(median_tab) % 2 == 0:\n",
        "        print(\"median of \" + colname + \" numbers : \" + str((median_tab[middle-1] + median_tab[middle]) / 2) + \"\\n\")\n",
        "    else:\n",
        "        print(\"median of \" + colname + \" numbers : \" + str(median_tab[middle]) + \"\\n\")\n",
        "\n",
        "# mean concept and keywords number per document\n",
        "MeanAndMedianArrayLength(df, \"concepts\")\n",
        "MeanAndMedianArrayLength(df, \"keywords\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean of concepts numbers : 10.03375\n",
            "median of concepts numbers : 10.0\n",
            "\n",
            "mean of keywords numbers : 19.80065\n",
            "median of keywords numbers : 20.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V82TF7cMXlEr",
        "colab_type": "text"
      },
      "source": [
        "Create Graph\n",
        "\n",
        "Blank node _x = une ressource\n",
        "_x :title col.title\n",
        "_x :id col.id\n",
        "_x :language col.langage\n",
        "_x :type col.type\n",
        "_x :keyword :design\n",
        "_x :concept :URI_DBPEDIA/ressource\n",
        "\n",
        ":design rdf:type :keyword\n",
        "\n",
        ":URI_DBPEDIA/ressource rdf:type :concept\n",
        "\n",
        "Détecter les ressources qui ont un caractère proche"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX1imUogXtqL",
        "colab_type": "text"
      },
      "source": [
        "### **How to request the fuseki's API**\n",
        "\n",
        "First install the module SPARQLWrapper with anaconda's terminal :\n",
        "- *Choose the right environnement*\n",
        "- *Write this piece of code : 'pip install SPARQLWrapper'*\n",
        "- *Documentation : 'https://rdflib.github.io/sparqlwrapper/'*\n",
        "\n",
        "Next you need to deploy the Fuseki's server :\n",
        "- *Go to \"/fuseki_server/\" folder*\n",
        "- *Launch the \"/fuseki-server.bate*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enxP9xlcYLD6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "96baec13-3547-4ae6-8b73-73927ceabcfa"
      },
      "source": [
        "!pip install SPARQLWrapper"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: SPARQLWrapper in /usr/local/lib/python3.6/dist-packages (1.8.4)\n",
            "Requirement already satisfied: rdflib>=4.0 in /usr/local/lib/python3.6/dist-packages (from SPARQLWrapper) (4.2.2)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.6/dist-packages (from rdflib>=4.0->SPARQLWrapper) (0.6.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib>=4.0->SPARQLWrapper) (2.4.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from isodate->rdflib>=4.0->SPARQLWrapper) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDd4nvYaZEcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from SPARQLWrapper import SPARQLWrapper, JSON\n",
        "\n",
        "server_URL = \"http://localhost:3030/your_service/sparql\"\n",
        "\n",
        "#sparql = SPARQLWrapper(server_URL)\n",
        "#sparql.setQuery(\"\"\"\n",
        "#    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
        "#    SELECT ?label\n",
        "#    WHERE { <http://dbpedia.org/resource/Asturias> rdfs:label ?label }\n",
        "#\"\"\")\n",
        "#sparql.setReturnFormat(JSON)\n",
        "#results = sparql.query().convert()\n",
        "\n",
        "#for result in results[\"results\"][\"bindings\"]:\n",
        "    #print(result[\"label\"][\"value\"])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}